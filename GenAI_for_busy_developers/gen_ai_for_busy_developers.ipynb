{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Environment configuration"
      ],
      "metadata": {
        "id": "-JCZjzn2YRb5"
      },
      "id": "-JCZjzn2YRb5"
    },
    {
      "cell_type": "code",
      "id": "y0SW81QXg58nZYK9hH69vIy7",
      "metadata": {
        "tags": [],
        "id": "y0SW81QXg58nZYK9hH69vIy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461447799,
          "user_tz": -60,
          "elapsed": 13113,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "4711e08c-a105-47f1-b7f4-d759b655ae40"
      },
      "source": [
        "%pip install -q --upgrade --user google-cloud-aiplatform==1.36.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-vertexai 0.1.1 requires google-cloud-aiplatform<2.0.0,>=1.44.0, but you have google-cloud-aiplatform 1.36.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
      ],
      "metadata": {
        "id": "v2U0MQFIYPae"
      },
      "id": "v2U0MQFIYPae"
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "import time\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "i-7ucTOHYvkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461454194,
          "user_tz": -60,
          "elapsed": 1023,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0e3252ec-3fd0-436a-92a7-f1ba936ccecc"
      },
      "id": "i-7ucTOHYvkY",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, you will need to authenticate your environment. To do this, run the new cell below. This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ],
      "metadata": {
        "id": "ykSn6K9DY64j"
      },
      "id": "ykSn6K9DY64j"
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "2iKJhdCzYz9y",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461471240,
          "user_tz": -60,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "2iKJhdCzYz9y",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vertex AI setup"
      ],
      "metadata": {
        "id": "OJNFGEHPbvXp"
      },
      "id": "OJNFGEHPbvXp"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet langchain langchain-core langchain-google-vertexai chromadb wikipedia"
      ],
      "metadata": {
        "id": "6KH1zeltb0ux",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461497909,
          "user_tz": -60,
          "elapsed": 16357,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "6KH1zeltb0ux",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from pprint import pprint\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_google_vertexai import VertexAI\n",
        "\n",
        "model = VertexAI(model_name=\"gemini-pro\", temperature=0.0)"
      ],
      "metadata": {
        "id": "yxtQ7jyJcLXN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461514521,
          "user_tz": -60,
          "elapsed": 6514,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "yxtQ7jyJcLXN",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Invoking model\n"
      ],
      "metadata": {
        "id": "eJ4_ICpeZTQM"
      },
      "id": "eJ4_ICpeZTQM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Standrd invoke"
      ],
      "metadata": {
        "id": "XcVTKr54aen4"
      },
      "id": "XcVTKr54aen4"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"\"\"Question: {question}\"\"\")\n",
        "\n",
        "question = \"Why python is not a great programming language?\"\n",
        "\n",
        "model.invoke(prompt.format(question=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "cJtsD87PcmxI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461522862,
          "user_tz": -60,
          "elapsed": 3538,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "2a5cc47a-f75c-48ea-f33a-3bd55c36b124"
      },
      "id": "cJtsD87PcmxI",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**Limitations of Python:**\\n\\n* **Speed:** Python is an interpreted language, which means it is slower than compiled languages like C++ or Java. This can be a disadvantage for performance-intensive applications.\\n* **Memory Management:** Python uses automatic memory management, which can lead to memory leaks if not handled properly.\\n* **Concurrency:** Python's Global Interpreter Lock (GIL) limits the number of threads that can run concurrently, which can hinder performance in multithreaded applications.\\n* **Type Safety:** Python is a dynamically typed language, which means that data types are not checked at compile time. This can lead to errors that are difficult to detect.\\n* **Limited Library Support:** While Python has a large standard library, it may not have all the necessary libraries for specialized applications.\\n* **Lack of Low-Level Control:** Python does not provide direct access to low-level system resources, which can be a limitation for certain types of applications.\\n* **Security Concerns:** Python's dynamic nature and lack of type safety can make it vulnerable to security exploits.\\n* **Not Suitable for Large-Scale Systems:** Python's limitations in speed, memory management, and concurrency make it less suitable for large-scale systems that require high performance and reliability.\\n* **Limited Cross-Platform Compatibility:** While Python is generally cross-platform, it may encounter compatibility issues when running on different operating systems or hardware architectures.\\n* **Lack of Support for Parallel Programming:** Python's GIL makes it difficult to implement efficient parallel programming, which can be a disadvantage for applications that require high levels of parallelism.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LCEL"
      ],
      "metadata": {
        "id": "HzS0TJNUbMqa"
      },
      "id": "HzS0TJNUbMqa"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(\"\"\"Question: {question}\"\"\")\n",
        "\n",
        "chain = prompt | model\n",
        "chain.invoke({\"question\": question})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "50ZxbJDqcn0k",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461530837,
          "user_tz": -60,
          "elapsed": 4142,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6b7c6162-ef3f-4ac7-981c-de6e17ebeaa4"
      },
      "id": "50ZxbJDqcn0k",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"**Limitations of Python:**\\n\\n* **Speed:** Python is an interpreted language, which means it is slower than compiled languages like C++ or Java. This can be a disadvantage for performance-intensive applications.\\n* **Memory Management:** Python uses automatic memory management, which can lead to memory leaks if not handled properly.\\n* **Concurrency:** Python's Global Interpreter Lock (GIL) limits the number of threads that can run concurrently, which can hinder performance in multithreaded applications.\\n* **Type Safety:** Python is a dynamically typed language, which means that data types are not checked at compile time. This can lead to errors that are difficult to detect.\\n* **Limited Library Support:** While Python has a large standard library, it may not have all the necessary libraries for specialized applications.\\n* **Lack of Low-Level Control:** Python provides limited access to low-level system resources, which can be a disadvantage for applications that require fine-grained control.\\n* **Security Concerns:** Python's dynamic nature and lack of type safety can make it vulnerable to security exploits.\\n* **Not Suitable for Large-Scale Systems:** Python's limitations in speed, memory management, and concurrency make it less suitable for large-scale systems that require high performance and reliability.\\n* **Limited Cross-Platform Compatibility:** While Python is generally cross-platform, some libraries and modules may not be compatible with all platforms.\\n* **Lack of Native Support for Parallelism:** Python's GIL prevents true parallelism, which can limit performance in applications that require extensive parallel processing.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare test data"
      ],
      "metadata": {
        "id": "m0qmbwtGbRkn"
      },
      "id": "m0qmbwtGbRkn"
    },
    {
      "cell_type": "code",
      "source": [
        "short_file = \"./luna_nozava.txt\"\n",
        "\n",
        "with open(short_file, \"r\") as f:\n",
        "    short_context = f.read()\n",
        "\n",
        "long_file = \"./ridge_forrester.txt\"\n",
        "\n",
        "with open(long_file, \"r\") as f:\n",
        "    long_context = f.read()"
      ],
      "metadata": {
        "id": "t_Er8ZUnP5td",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461578052,
          "user_tz": -60,
          "elapsed": 531,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "t_Er8ZUnP5td",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic query based on context"
      ],
      "metadata": {
        "id": "mNg-ixRHbWtr"
      },
      "id": "mNg-ixRHbWtr"
    },
    {
      "cell_type": "code",
      "source": [
        "promtp_template = \"\"\"\n",
        "    You are expert on The Bold and the Beautiful tv series.\n",
        "    Based on context: {context}\n",
        "    Answer the question: {question}\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(promtp_template)\n",
        "\n",
        "questions =  \"\\n\".join([\n",
        "    \"What is the name of described character?\",\n",
        "    \"Did she cheated on someone? If yes, who?\",\n",
        "    \"What are her addictions?\",\n",
        "])\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "# short_context - description of one of the characters\n",
        "chain.invoke({\"context\": short_context, \"question\": questions })\n",
        "\n"
      ],
      "metadata": {
        "id": "s4K-B-IIUeIb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461606887,
          "user_tz": -60,
          "elapsed": 1577,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "86887fac-ba6e-48ec-872c-1a5c82b84ca2"
      },
      "id": "s4K-B-IIUeIb",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured output"
      ],
      "metadata": {
        "id": "9pyrdmT6bfOl"
      },
      "id": "9pyrdmT6bfOl"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser"
      ],
      "metadata": {
        "id": "Dgr3hIide8OE",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461609557,
          "user_tz": -60,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "Dgr3hIide8OE",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QA(BaseModel):\n",
        "  q: str = Field(description=\"question asked\")\n",
        "  a: str = Field(description=\"answer to question\")\n",
        "\n",
        "class PearsonCard(BaseModel):\n",
        "  questionsAndAnswers: List[QA] = Field(description=\"list of questions and answers\")\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = JsonOutputParser(pydantic_object=PearsonCard)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"\"\"\n",
        "    You are expert on The Bold and the Beautiful tv series.\n",
        "    Based on context: {context}\n",
        "    Answer the questions: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\",\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "\n",
        "chain = prompt | model | parser\n",
        "\n",
        "chain.invoke({\"context\": short_context, \"question\": questions})"
      ],
      "metadata": {
        "id": "5upYdTFPiOAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461614101,
          "user_tz": -60,
          "elapsed": 2182,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "d477c54f-2ed7-483a-93cf-efd2c66d2c9b"
      },
      "id": "5upYdTFPiOAJ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'questionsAndAnswers': [{'q': 'What is the name of described character?',\n",
              "   'a': 'Luna Nozawa'},\n",
              "  {'q': 'Did she cheated on someone? If yes, who?',\n",
              "   'a': 'Yes, she cheated on R.J. Forrester with Zende Forrester Dominguez'},\n",
              "  {'q': 'What are her addictions?', 'a': 'She is addicted to narcotics'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Even more structured output"
      ],
      "metadata": {
        "id": "TgF6POnRbhtA"
      },
      "id": "TgF6POnRbhtA"
    },
    {
      "cell_type": "code",
      "source": [
        "# to see what is happening under the hood\n",
        "#from langchain.globals import set_verbose, set_debug\n",
        "#set_debug(True)\n",
        "#set_verbose(True)\n",
        "\n",
        "# Define your desired data structure.\n",
        "class PearsonCard(BaseModel):\n",
        "  name: str = Field(description=\"name of the character?\")\n",
        "  cheated: bool = Field(description=\"did she cheated on someone?\")\n",
        "  cheated_on: List[str] = Field(description=\"who she cheated on?\")\n",
        "\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = PydanticOutputParser(pydantic_object=PearsonCard)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"\"\"\n",
        "    You are expert on The Bold and the Beautiful tv series.\n",
        "    Based on context: {context}\n",
        "    Answer the question: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\",\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "    )\n",
        "\n",
        "chain = prompt | model | parser\n",
        "\n",
        "chain.invoke({\"context\": short_context, \"question\": questions})"
      ],
      "metadata": {
        "id": "IyUA8HtSavBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461645910,
          "user_tz": -60,
          "elapsed": 1460,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "f52b6076-7e73-405f-ab6d-b3aaa176413d"
      },
      "id": "IyUA8HtSavBw",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PearsonCard(name='Luna Nozawa', cheated=True, cheated_on=['R.J. Forrester'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple wrapper for asking questions"
      ],
      "metadata": {
        "id": "ds_P_4psYgB2"
      },
      "id": "ds_P_4psYgB2"
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(context: str, questions: List[str], returnType: object) -> object:\n",
        "  parser = PydanticOutputParser(pydantic_object=returnType)\n",
        "  prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on context: {context}\n",
        "    Answer the question: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\",\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "  )\n",
        "  chain = prompt | model | parser\n",
        "  return chain.invoke({\"context\": context, \"question\": questions})\n",
        "\n",
        "class Answer(BaseModel):\n",
        "  questionAsked: str = Field(description=\"question asked\")\n",
        "  answer: bool = Field(description=\"answer to question as boolean value\")\n",
        "\n",
        "ask(short_context, [\"Did character cheated on someone?\"], Answer)"
      ],
      "metadata": {
        "id": "GQnAwSScYfjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461653084,
          "user_tz": -60,
          "elapsed": 2437,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7a5ec9c8-ebad-4b93-852d-cde244ee7901"
      },
      "id": "GQnAwSScYfjc",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Answer(questionAsked='Did character cheated on someone?', answer=True)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic test of simple properties"
      ],
      "metadata": {
        "id": "c3_bxZFQYU6s"
      },
      "id": "c3_bxZFQYU6s"
    },
    {
      "cell_type": "code",
      "source": [
        "response = ask(short_context, [\"Did character cheated on someone?\"], Answer)\n",
        "assert response.answer == True"
      ],
      "metadata": {
        "id": "WpMtKj0tjjA4"
      },
      "id": "WpMtKj0tjjA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_scenarios = [\n",
        "    {\"question\": \"Did character cheated on someone?\",   \"expected\": True},\n",
        "    {\"question\": \"Did character has alcohol problem?\",  \"expected\": False},\n",
        "    {\"question\": \"Did character uses drugs?\",           \"expected\": True}\n",
        "]\n",
        "\n",
        "for scenario in test_scenarios:\n",
        "  response = ask(short_context, [scenario[\"question\"]], Answer)\n",
        "  assert response.answer == scenario[\"expected\"], f\"Expected {scenario['expected']} for {scenario['question']}\"\n"
      ],
      "metadata": {
        "id": "_yfVr6bnfRXP"
      },
      "id": "_yfVr6bnfRXP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing complex resonses"
      ],
      "metadata": {
        "id": "HoTyAQotgYEw"
      },
      "id": "HoTyAQotgYEw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Complex resonse"
      ],
      "metadata": {
        "id": "PogKdUP7hayg"
      },
      "id": "PogKdUP7hayg"
    },
    {
      "cell_type": "code",
      "source": [
        "class DesciptiveResponse(BaseModel):\n",
        "  questionAsked: str = Field(description=\"question asked\")\n",
        "  answer: str = Field(description=\"answer to question\")\n",
        "\n",
        "\n",
        "ask(short_context, [\"How character was introduced to the series?\"], DesciptiveResponse)"
      ],
      "metadata": {
        "id": "huaYbsdHheT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461670268,
          "user_tz": -60,
          "elapsed": 1149,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "3a90e46c-27a0-48ad-e103-6808d62411e3"
      },
      "id": "huaYbsdHheT-",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DesciptiveResponse(questionAsked='How character was introduced to the series?', answer='Luna was introduced as she entered the family mansion with an armload of supplies for Eric and R.J. Forrester, to help create the new couture line they were working on in secret.')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluator"
      ],
      "metadata": {
        "id": "sCi_sJVVhSgl"
      },
      "id": "sCi_sJVVhSgl"
    },
    {
      "cell_type": "code",
      "source": [
        "# taken from https://github.com/davidtan-tw/testing-llms-demo/blob/main/testing_llms_demo/tests/test_llm_based_tests.py\n",
        "from pprint import pprint\n",
        "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
        "\n",
        "def evaluate_llm_response(input_prompt, generated_response):\n",
        "    evaluator_prompt = PromptTemplate.from_template(\"\"\"\n",
        "    You are an evaluator, focused on checking that Generated Response contains only key information\n",
        "    that is present in Input Prompt\n",
        "\n",
        "    Here's an Input Prompt: {input_prompt}\n",
        "    Here's the Generated Response: {generated_response}\n",
        "\n",
        "    Instruction: Return a valid JSON object with 4 keys:\n",
        "    result (SATISFACTORY or NOT_SATISFACTORY),\n",
        "    reason (explaining rationale for result),\n",
        "    input_prompt,\n",
        "    generated_response\n",
        "    result must be SATISFACTORY only if Generated Response match all the responsibilities listed in Input Prompt\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    evaluator_runnable = evaluator_prompt | model | SimpleJsonOutputParser()\n",
        "    evaluation_result = evaluator_runnable.invoke(\n",
        "        {\"input_prompt\": input_prompt, \"generated_response\": generated_response})\n",
        "    #pprint(evaluation_result)\n",
        "\n",
        "    return evaluation_result"
      ],
      "metadata": {
        "id": "ZisfzTu2hRnH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461672808,
          "user_tz": -60,
          "elapsed": 379,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "ZisfzTu2hRnH",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask2(context: str, questions: List[str], returnType: BaseModel) -> (str, BaseModel):\n",
        "  parser = PydanticOutputParser(pydantic_object=returnType)\n",
        "  prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on context: {context}\n",
        "    Answer the question: {question}\n",
        "    {format_instructions}\n",
        "    \"\"\",\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        "  )\n",
        "  final_prompt = prompt.format(context = context, question = questions)\n",
        "  chain = prompt | model | parser\n",
        "  result = chain.invoke({\"context\": context, \"question\": questions})\n",
        "  return final_prompt, result"
      ],
      "metadata": {
        "id": "cBylocNml5cv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461678233,
          "user_tz": -60,
          "elapsed": 326,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "cBylocNml5cv",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How character was introduced to the series? Give answer in 7 words.\"\n",
        "input_prompt, response = ask2(short_context, [question], DesciptiveResponse)\n",
        "evaluation_result = evaluate_llm_response(input_prompt, response)\n",
        "\n",
        "print(evaluation_result['result'])\n",
        "print(evaluation_result['reason'])"
      ],
      "metadata": {
        "id": "QHTzvQqbip5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461692361,
          "user_tz": -60,
          "elapsed": 9432,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "03b23ce6-3eee-4ddf-ff10-ebfa7fa52d64"
      },
      "id": "QHTzvQqbip5u",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SATISFACTORY\n",
            "The Generated Response contains only key information that is present in the Input Prompt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Long context"
      ],
      "metadata": {
        "id": "IMGTZnw-ovw5"
      },
      "id": "IMGTZnw-ovw5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How it can fail"
      ],
      "metadata": {
        "id": "5kVwJsIvuUnM"
      },
      "id": "5kVwJsIvuUnM"
    },
    {
      "cell_type": "code",
      "source": [
        "model = VertexAI(model_name=\"text-bison\")\n",
        "ask(long_context, [\"How character was introduced to the series?\"], DesciptiveResponse)"
      ],
      "metadata": {
        "id": "KvM11V8roy59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "executionInfo": {
          "status": "error",
          "timestamp": 1711461700488,
          "user_tz": -60,
          "elapsed": 4587,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "296d62ba-4dd4-4841-936c-5d6daa13b30b"
      },
      "id": "KvM11V8roy59",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_core.language_models.llms:Retrying langchain_google_vertexai.llms._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InvalidArgument: 400 The request cannot be processed. The most likely reason is that the provided input exceeded the model's input token limit..\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2a6661100f59>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVertexAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-bison\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlong_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"How character was introduced to the series?\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDesciptiveResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-8ccb906f774e>\u001b[0m in \u001b[0;36mask\u001b[0;34m(context, questions, returnType)\u001b[0m\n\u001b[1;32m      9\u001b[0m   )\n\u001b[1;32m     10\u001b[0m   \u001b[0mchain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"question\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAnswer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2307\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2308\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2309\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m   2310\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         return (\n\u001b[0;32m--> 248\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    567\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    568\u001b[0m         \u001b[0mprompt_strings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_strings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 )\n\u001b[1;32m    747\u001b[0m             ]\n\u001b[0;32m--> 748\u001b[0;31m             output = self._generate_helper(\n\u001b[0m\u001b[1;32m    749\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0mflattened_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_managers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/llms.py\u001b[0m in \u001b[0;36m_generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             output = (\n\u001b[0;32m--> 593\u001b[0;31m                 self._generate(\n\u001b[0m\u001b[1;32m    594\u001b[0m                     \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m                     \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_vertexai/llms.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, prompts, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0mgenerations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgeneration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 res = _completion_with_retry(\n\u001b[0m\u001b[1;32m    385\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_vertexai/llms.py\u001b[0m in \u001b[0;36m_completion_with_retry\u001b[0;34m(llm, prompt, stream, is_gemini, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtelemetry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_user_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_completion_with_retry_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_gemini\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoSleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_for_next_attempt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m  \u001b[0;31m# type: ignore[no-any-return]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/nap.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmocked\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create vector store"
      ],
      "metadata": {
        "id": "HWpv1ZYEuXf5"
      },
      "id": "HWpv1ZYEuXf5"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"./ridge_forrester.txt\")\n",
        "doc = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(doc)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=VertexAIEmbeddings(\"textembedding-gecko\"))\n"
      ],
      "metadata": {
        "id": "e_0iEvFtqf4T",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461716459,
          "user_tz": -60,
          "elapsed": 7176,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "id": "e_0iEvFtqf4T",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual vectorstore usage"
      ],
      "metadata": {
        "id": "hFC7krKkvprU"
      },
      "id": "hFC7krKkvprU"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever()\n",
        "retrieved_docs = retriever.invoke(\"Did character cheated on someone?\")\n",
        "\n",
        "pprint(retrieved_docs)"
      ],
      "metadata": {
        "id": "pTohmRCmuZ6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461722222,
          "user_tz": -60,
          "elapsed": 1103,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "7ea17ce4-beb0-44f4-81dc-f5bff72e66ea"
      },
      "id": "pTohmRCmuZ6m",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content=\"At the start of the series, Ridge is secretly dating [[Caroline Spencer Forrester|Caroline Spencer]]. Caroline's father, Bill Spencer, hears about Ridge's bad reputation with women and asks him not to see Caroline again. Later that evening, Ridge proposes to Caroline out of spite. Bill Spencer hires a private investigator to look into Ridge and see if he is mistreating Caroline. Bill tries to trust Ridge and calls the private investigator off, but the private investigator had already taken a picture of Ridge sleeping with a former fling, Alex Simpson in a hotel room having sex and sent it to Bill Spencer. On Caroline's wedding day, Bill tells Caroline what he has found. Caroline is heartbroken and angry at her father and decides to go on with the wedding anyway. As she is walking down the aisle, she faints and is taken to the hospital, leaving Ridge at the alter. After she is released, Ridge realizes he really does love her, but Caroline decides she needs to live on her own for\", metadata={'source': '/content/ridge_forrester.txt'}),\n",
            " Document(page_content=\"At the start of the series, Ridge is secretly dating [[Caroline Spencer Forrester|Caroline Spencer]]. Caroline's father, Bill Spencer, hears about Ridge's bad reputation with women and asks him not to see Caroline again. Later that evening, Ridge proposes to Caroline out of spite. Bill Spencer hires a private investigator to look into Ridge and see if he is mistreating Caroline. Bill tries to trust Ridge and calls the private investigator off, but the private investigator had already taken a picture of Ridge sleeping with a former fling, Alex Simpson in a hotel room having sex and sent it to Bill Spencer. On Caroline's wedding day, Bill tells Caroline what he has found. Caroline is heartbroken and angry at her father and decides to go on with the wedding anyway. As she is walking down the aisle, she faints and is taken to the hospital, leaving Ridge at the alter. After she is released, Ridge realizes he really does love her, but Caroline decides she needs to live on her own for\", metadata={'source': './ridge_forrester.txt'}),\n",
            " Document(page_content=\"At one point Hope makes a shocking decision to end her marriage to Liam so he can take care of his living daughter Kelly and Steffy's adopted daughter, who Hope grew very fond of. She also decided to become Douglas's mother and Thomas's wife. Ridge is very supportive because he wants his grandson to have a mother as well as he wants to see Steffy and Liam being a family with their daughter once more. He is unaware that his son knows that Steffy's adopted daughter is in fact Hope's and Liam's daughter and that Thomas's fabricated a fake letter from Caroline which made Hope believe that she should raise Douglas. Unaware of Thomas's lies Ridge defends the idea Hope and Thomas to his wife [[Brooke Logan Forrester]] that wants her daughter to go back to Liam Spencer. Liam moves in with Steffy and the children and at one point he has sex with his ex wife, but under the influence of drugs that Thomas has secretly given him.\", metadata={'source': '/content/ridge_forrester.txt'}),\n",
            " Document(page_content=\"At one point Hope makes a shocking decision to end her marriage to Liam so he can take care of his living daughter Kelly and Steffy's adopted daughter, who Hope grew very fond of. She also decided to become Douglas's mother and Thomas's wife. Ridge is very supportive because he wants his grandson to have a mother as well as he wants to see Steffy and Liam being a family with their daughter once more. He is unaware that his son knows that Steffy's adopted daughter is in fact Hope's and Liam's daughter and that Thomas's fabricated a fake letter from Caroline which made Hope believe that she should raise Douglas. Unaware of Thomas's lies Ridge defends the idea Hope and Thomas to his wife [[Brooke Logan Forrester]] that wants her daughter to go back to Liam Spencer. Liam moves in with Steffy and the children and at one point he has sex with his ex wife, but under the influence of drugs that Thomas has secretly given him.\", metadata={'source': './ridge_forrester.txt'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask(retrieved_docs, [\"Did character cheated on someone?\"], DesciptiveResponse)"
      ],
      "metadata": {
        "id": "-agEmduwvf-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461726239,
          "user_tz": -60,
          "elapsed": 1207,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "6e565241-7efa-4715-a00d-359f664e9e12"
      },
      "id": "-agEmduwvf-X",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DesciptiveResponse(questionAsked='Did character cheated on someone?', answer='Yes, Ridge cheated on Caroline with Alex Simpson.')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorstore as part of chain"
      ],
      "metadata": {
        "id": "bC5CGAvWvt7x"
      },
      "id": "bC5CGAvWvt7x"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "prompt = PromptTemplate.from_template(\"\"\"\n",
        "    Based on context: {context}\n",
        "    Answer the question: {question}\n",
        "    \"\"\")\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever,  \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain.invoke(\"Did character cheated on someone?\")"
      ],
      "metadata": {
        "id": "MLcFTGL3vwcR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461730623,
          "user_tz": -60,
          "elapsed": 800,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "00313f94-49c9-4002-b6be-a01b404bac00"
      },
      "id": "MLcFTGL3vwcR",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yes, Ridge cheated on Caroline with Alex Simpson.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools"
      ],
      "metadata": {
        "id": "cX7EajzgZCA8"
      },
      "id": "cX7EajzgZCA8"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=100)\n",
        "tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
        "\n",
        "\n",
        "print(tool.description)\n",
        "print(tool.args)"
      ],
      "metadata": {
        "id": "_hI1lQLYIcST",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461737594,
          "user_tz": -60,
          "elapsed": 1056,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeeb048a-3699-445e-d953-a8ae689b4fd0"
      },
      "id": "_hI1lQLYIcST",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\n",
            "{'query': {'title': 'Query', 'type': 'string'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# note: this code is not always working correctly :(\n",
        "from langchain.agents import AgentType, initialize_agent\n",
        "\n",
        "\n",
        "agent = initialize_agent([tool], model, verbose=True)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are expert on The Bold and the Beautiful tv series.\n",
        "    Based on context: {context}\n",
        "    Answer the question: {question}\n",
        "  \"\"\"\n",
        ")\n",
        "agent.invoke(prompt.format(context= short_context, question= \"What is character's name? What year was actor playint this character born?\"))\n"
      ],
      "metadata": {
        "id": "XAzTYOZ3eXc2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1711461776167,
          "user_tz": -60,
          "elapsed": 36516,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251d9160-dfb2-4a07-9de5-ae1775082164"
      },
      "id": "XAzTYOZ3eXc2",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Luna Nozawa\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Luna Nozawa\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "\n",
            "Action: wikipedia\n",
            "Action Input: Luna Nozawa\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Question: What is character's name? What year was actor playing this character born?\n",
            "Thought: The question asks for the character's name and the year the actor playing the character was born.\n",
            "Action: wikipedia\n",
            "Action Input: Lisa Yamada\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: List of The Bold and the Beautiful characters (2020s)\n",
            "Summary: The Bold and the Beautiful is a\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': '\\n    You are expert on The Bold and the Beautiful tv series.\\n    Based on context: {{Infobox soap character\\n|image1 = File:lunan.jpg\\n|name = Luna Nozawa\\n|caption1 = Lisa Yamada as Luna Nozawa\\n|portrayer = [[Lisa Yamada]]\\n|status = Present, Contract\\n|years = 2023-\\n|first = September 13, 2023\\n|creator = [[Bradley Bell]]\\n|introducer = [[Bradley Bell]]\\n|family = [[Nozawa family]] \\n|gender = Female\\n|born = 2002 \\n|age = 20 \\n|parents =[[Poppy Nozawa]] (mother)\\n|siblings = \\n|romances = [[R.J. Forrester]] <br> [[Zende Forrester Dominguez]] \\n|aunts/uncles = [[Li Finnegan]] (maternal aunt)\\n|nieces/nephews = \\n|cousins = [[Finn Finnegan|John \"Finn\" Finnegan]] (adopted cousin) <br> [[Hayes Finnegan]] (adopted cousin once removed)\\n|grandparents = \\n|series = [[The Bold and the Beautiful]]\\n|occupation = Intern at [[Forrester Creations]] <br> Assistant fashion designer to [[Eric Forrester]] \\n|last = \\n|cause =}}\\n\\'\\'\\'Luna Nozawa\\'\\'\\' is a character on [[The Bold and the Beautiful]], portrayed by [[Lisa Yamada]].\\n\\nLuna was introduced as the daughter of [[Poppy Nozawa]], the niece of Dr. [[Li Finnegan]], and the adoptive cousin of Dr. [[Finn Finnegan|Johnathan \"Finn\" Finnegan]].\\n\\n== Background ==\\nLuna was born and raised by Poppy in The Bay area, Los Angeles, California. Luna and Poppy are self-described \"hippies\" and \"free-spirits\", unlike Li and her unnamed father who are said to be \"very driven\".\\n\\nLuna is currently an Intern at [[Forrester Creations]]; secretly, she also assists [[Eric Forrester]] with his \"grand finale\" fashion line, at the [[Forrester Mansion]]. Due to the fallout caused by Finn\\'s biological mother [[Sheila Carter]] and her past/present involvement with the [[Forrester family]] - primarily regarding Finn\\'s and wife [[Steffy Forrester]]\\'s [[Episode 8774|attempted murder]] - all members of Luna\\'s family have urged her to stay away and leave her internship.\\n\\n== Storylines ==\\nLuna was introduced as she entered the family mansion with an armload of supplies for Eric and R.J. Forrester, to help create the new couture line they were working on in secret. When Eric asked partner [[Donna Logan]] why she hired Luna over all the other applicants, she had to admit she never looked at her resume, but when Luna pitched in on reception they had a nice talk and she made the decision. \\n\\nHowever, while Eric, Donna and R.J. felt they could trust Luna, the young woman then took a phone call from her mother, [[Poppy]], who was upset to learn she was in Los Angeles and warned her to stay away from the family. Poppy had made several further calls, ordering Luna to leave her internship, and reminding her about what happened to Li and Finn.\\n\\nAfter Luna assured R.J. she would keep Eric’s condition a secret, he insisted she tell him a secret of her own. She told him she was raised by her mother, who was a bit of a free spirit, though her grandfather and aunt are more driven. R.J. was immediately smitten with Luna, and has attempted to console her over the upset she presents regarding her family. Li found Luna in the Design Office at Forrester Creations, confused as to why she is in Los Angeles, and ordered that she resign. After complying, R.J. implores Luna to reconsider leaving the company, and they kiss intently.\\n\\nAfter Luna was reunited with Finn, Luna tells him that the reason, she and her mother lost contact with him for years is because of Li. Then after Finn left, Li returned to the Design Office at Forrester Creations, R.J. implore Li to let Luna stay, but she refused. Then Luna asked R.J. to leave the room in order to speak to her aunt alone. After R.J. left, Luna blasted Li for the way she treated her mother and her for years, never invited her and her mother to Finn and Steffy\\'s wedding, and never comforted her, when Finn was shot. Luna also informed Li, that fashion is her dream, since she was a child, she would know that, if Li would get to know Luna, and no one tells her, what she\\'ll do with her own life, especially Li. \\n\\n== Crimes and Misdeeds ==\\n\\n* Cheated on boyfriend [[R.J. Forrester]] with [[Zende Forrester Dominguez]], whilst under the influence of narcotics (2024).\\n\\n== Maladies and Injuries ==\\n\\n* Accidentally consumed several of [[Poppy Nozawa]]\\'s narcotic \"mints\", followed by alcohol, causing a severe high (2024).\\n* Taken advantage of by [[Zende Forrester Dominguez]], whilst inebriated on narcotics (2024).\\n\\n== References ==\\n\\n# https://www.soapsindepth.com/posts/the-bold-the-beautiful/luna-on-the-bold-and-the-beautiful-lisa-yamada\\n\\n[[Category:Female Characters]]\\n[[Category:Interns]]\\n[[Category:Forrester Workers]]\\n[[Category:2023]]\\n[[Category:Current characters]]\\n\\n    Answer the question: What is character\\'s name? What year was actor playint this character born?\\n  ',\n",
              " 'output': 'Agent stopped due to iteration limit or time limit.'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OJNFGEHPbvXp",
        "XcVTKr54aen4",
        "HzS0TJNUbMqa",
        "mNg-ixRHbWtr",
        "TgF6POnRbhtA",
        "ds_P_4psYgB2"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}